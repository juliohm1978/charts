# Valores referentes ao Deployment/Statefulset/DaemonSet
deployment:

  ## Escikga entre Deployments, StatefulSets ou DaemonSets.
  ## Comente e descomente os blocos que deseja usar.

  # DEPLOYMENT Estrategia de update para deploy de nova versao
  kind: Deployment
  strategy: {}
  #   type: RollingUpdate  ## valores: RollingUpdate | Recreate
  #   rollingUpdate:
  #     maxSurge: 1
  #     maxUnavailable: 0

  # DEPLOYMENT Estrategia de update para deploy de nova versao
  # kind: DaemonSet
  # strategy:
  #   type: RollingUpdate  ## valores: RollingUpdate | OnDelete
  #   rollingUpdate:
  #     maxUnavailable: 1

  # STATEFULSET
  # kind: StatefulSet
  # podManagementPolicy: OrderedReady  ## valores: OrderedReady | Parallel
  # strategy:
  #   type: RollingUpdate  ## valores: RollingUpdate | OnDelete
  #   rollingUpdate:
  #     # CUIDADO! Confira a documentacao para entender o que faz o 'partition'
  #     # https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies
  #     partition: 0

  replicaCount: 1

  labels: {}
    # label1: value1
    # label2: value2

  annotations: {}
    # annot1: "valor1"
    # annot2: "valor2"

  # Tempo máximo de espeara até os Pods ficarem prontos
  progressDeadlineSeconds: 900

  # Máximo de historico de revisoes do RollingUpdate
  revisionHistoryLimit: 5

# Valores referentes ao Pod.
pod:
  image: ""
  tag: ""

  imagePullPolicy: IfNotPresent
  imagePullSecrets: []
    # - name: secret1
    # - name: secret2

  prometheusEnable: "true"
  prometheusPort: "9404"

  # Descomente para usar outra conta no Pod.
  # Use o valor "create: true" para criar um Service Account já com as
  # permissões definidas no "rules".
  serviceAccount:
    create: false
    # name: my-svc-account-name
    # roleType: ClusterRole
    # bindingType: ClusterRoleBinding
    # rules:
    #   - apiGroups:
    #     - ""
    #     resources:
    #     - pods
    #     - namespaces
    #     verbs:
    #     - get
    #     - list
    #     - watch

  annotations: {}
    # annot1: "valor1"
    # annot2: "valor2"

  labels: {}
    # label1: value1
    # label2: value2

  # Tempo esperado para o Pod matar os containers antes de soltar o Chuck Norris.
  terminationGracePeriodSeconds: 5

  # enableIdDeploy: Cria ID unico para cada deploy como label no pod template.
  #
  # Forca o spec do Deployment ficar diferente toda vez que
  # um 'helm install/upgrade' eh realizado.
  #
  # Usado em conjunto com 'imagePullPolicy: Always'
  #
  # Ajuda a renovar imagens docker que foram atualizadas sem mudar a tag.
  enableIdDeploy: false

  env: []
    # - name: VAR1
    #   value: "VAL1"
    # - name: VAR2
    #   value: "VAL2"

  # Equivalente ao Docker ENTRYPOINT
  command: []
    # - /path/to/binary/inside/container
    # - arg1
    # - arg2

  # Equivalente ao Docker CMD
  args: []
    # - arg3
    # - arg4
    # - arg5

  # ReadinessProbe e LivenessProbe
  # Tipos: httpGet ou tcpSocket.
  # 'path' e 'port' sao derivados, mas podem ser sobrescritos.

  # Inicia depois do startupProbe
  # Valores padrão do K8s
  readinessProbe:
    enabled: true
    type: httpGet
    # path: /Padrao_Nome_Do_Helm_Release_Sem_Sufixo *-deploy
    # port: Padrao_Primeira_Porta_Do_Service
    scheme: HTTP
    initialDelaySeconds: 0
    timeoutSeconds: 5
    periodSeconds: 10
    successThreshold: 1
    failureThreshold: 3

  # Inicia depois do startupProbe
  # Valores padrão do K8s
  livenessProbe:
    enabled: true
    type: httpGet
    # path: /Padrao_Nome_Do_Helm_Release_Sem_Sufixo *-deploy
    # port: Padrao_Primeira_Porta_Do_Service
    scheme: HTTP
    initialDelaySeconds: 0
    timeoutSeconds: 5
    periodSeconds: 10
    successThreshold: 1
    failureThreshold: 3

  # Tempo máximo de 15 mins para aplicação responder com sucesso
  startupProbe:
    enabled: true
    type: httpGet
    # path: /Padrao_Nome_Do_Helm_Release_Sem_Sufixo *-deploy
    # port: Padrao_Primeira_Porta_Do_Service
    scheme: HTTP
    initialDelaySeconds: 0
    timeoutSeconds: 3
    periodSeconds: 1
    successThreshold: 1
    failureThreshold: 900

  # Configura níveis específicos de segurança para o pod e container
  # https://kubernetes.io/docs/tasks/configure-pod-container/security-context/  
  podSecurityContext: {}
    #sysctls:
    #  - name: kernel.shm_rmid_forced
    #    value: "0"
    #  - name: net.ipv4.route.min_pmtu
    #    value: "552"
    #  - name: kernel.msgmax
    #    value: "65536"

  securityContext: {}
    #capabilities:
    #  add: ["NET_ADMIN"]

  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  nodeSelector: {}

  tolerations: []

  affinity: {}

  ## Mais configuracoes no spec do Pod
  extraPodConfig: {}
  
  # Containers que rodam antes dos containers de aplicacao
  # https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
  initContainers: []
    # - name: initContainer1
    #   image: nginx
    #   imagePullPolicy: Always
    #   command:
    #     - /bin/sh
    #     - -c
    #     - while true; do
    #         date;
    #         sleep 30;
    #       done;

  # Defina containers adicionais que deseja iniciar dentro do Pod.
  extraContainers: []
    # - name: extraContainer1
    #   image: nginx
    #   imagePullPolicy: Always
    #   command:
    #     - /bin/sh
    #     - -c
    #     - while true; do
    #         date;
    #         sleep 30;
    #       done;

# Para consistencia, o chart mapeia as portas do service ao container.
# Lembre-se de definir nome nas portas para ficar mais facil de entender
# este mapeamento quando diagnosticar o Yaml gerado.
#
# `targetPort` nao eh obrigatorio, mas quando definido sobrescreve o valor
# declarado no container do pod.
#
# `nodePort` soh pode ser usado com service type NodePort.
#
# `protocol` pode ser omitido. Padrao: TCP.
#
# NOTA: A primeira porta da lista eh usada no livenessProbe e readinessProbe.
service:
  type: ClusterIP
  ports: []
    # - name: http
    #   port: 80
    #   targetPort: 8080
    #   protocol: TCP
    #   nodePort: 30000
    
    # - name: https
    #   port: 443
    #   targetPort: 8443
    #   protocol: TCP
    # - name: porta1001
    #   port: 1001
    #   protocol: UDP

ingresses:
  annotations:
    kubernetes.io/ingress.class: nginx
  # domain: mydomain.com
  # tlsSecretName: mysecret1
  paths: []
  # - name: app
  #   domain: another-domain.com (opcional se especificado em ingresses. Sobrescreve o valor default)
  #   path: /
  #   annotations: {}
  #   disableTLS: true
  #   tlsSecretName: mysecret2
  #   pathType: ImplementationSpecific
  #
  #   ## Quando não especificado, servicePort usa a primeira porta do Service.
  #   servicePort: 9999
  #
  # - name: rest
  #   path: /api
  #   annotations:
  #     nginx.ingress.kubernetes.io/proxy-read-timeout: "300"

configMaps: []
  # - name: datasources
  #   mountPath: /environment
  #   mountSubPath: false (opcional, indica montagem das entradas do configMap como subPath)
  #   data:
  #     pgDataSource.ds: |
  #       JNDINAME="java:/jdbc/myjndiname"
  #       USERNAME=user
  #       PASSWORD="password"
  #       URL="jdbc:Cache://remote-host:1972/NOME_DATABASE"

  # Pode-se criar um configmap sem montá-lo como volume bastante não informar o mountPath
  # - name: environment
  #   data:
  #     LOCALE: pt_BR

## No caso de Deployments,  cria PVCs referenciados no volumeMounts.
## No caso de StatefulSets, cria volumeClaimTemplates referenciados no volumeMounts.
persistentVolumeClaims: []
  # - name: www
  #   readOnly: false
  #   mountPath: /caminho/dentro/do/container
  #   spec:
  #     accessModes: [ "ReadWriteOnce" ]
  #     storageClassName: "my-storage-class"
  #     resources:
  #       requests:
  #         storage: 1Gi

# Cria o PV diretamente no Pod, sem precisa do PVC
volumes: []
  # - name: dados
  #   mountPath: /dados/minha_aplicacao
  #   spec:
  #     nfs:
  #       server: 123.123.123.123
  #       path: /NFS_server/share

  # - name: meuvolume
  #   mountPath: /caminho/meuvolume
  #   spec:
  #     flexVolume:
  #       driver: juliohm/cifs
  #       options:
  #         server: 192.168.99.112
  #         share: /mount
  #         passwdMethod: env
  #       secretRef:
  #         name: client-credentials

  # - name: temporario
  #   mountPath: /caminho/temporario
  #   spec:
  #     emptyDir: {}

  # - name: logs
  #   mountPath: /var/log
  #   spec:
  #     hostPath:
  #       path: /var/log

  # - name: env-config
  #   mountPath: /etc/env-config
  #   spec:
  #     configMap:
  #       name: env-config

  # - name: from-secret
  #   mountPath: /secret-location
  #   readOnly: true
  #   spec:
  #     secret:
  #       secretName: mysecret

extraVolumeMounts: []
  # - mountPath: /etc/config/file
  #   name: config-map
  #   subPath: file

networkPolicies: []
  # - name: deny-all
  #   podSelector:
  #     function: "job"
  #   policyTypes:
  #     - Ingress
  #     - Egress
  # - name: deny-ingress
  #   policyTypes:
  #     - Ingress
  # - name: deny-egress
  #   policyTypes:
  #     - Egress
  # - name: permit-all
  #   policyTypes:
  #     - Ingress
  #     - Egress
  #   ingress:
  #     - {}
  #   egress:
  #     - {}
  # - name: permit-ingress
  #   policyTypes:
  #     - Ingress
  #   ingress:
  #     - {}
  # - name: permit-egress
  #   policyTypes:
  #     - Egress
  #   egress:
  #     - {}
  # - name: permit-ingress-http
  #   policyTypes:
  #     - Ingress
  #   ingress:
  #     - from:
  #       - ipBlock:
  #           cidr: 123.123.123.0/24
  #       ports:
  #         - protocol: TCP
  #           port: 80
  # - name: permit-egress-psql
  #   policyTypes:
  #     - Egress
  #   egress:
  #     - to:
  #       - ipBlock:
  #           cidr: 123.123.123.0/24
  #       ports:
  #         - protocol: TCP
  #           port: 5432

## Cria pontos adicionais de coleta e alertas específicos para esta aplicação.
## Normalmente, o Prometheus Operator já vem configurado para coletar métricas
## essenciais de todos os containers:  cpu, memória, network, etc.
##
## Confira a dos objetos da API do Operator
## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md
##
## É QUASE um espelho da configuração do Prometheus
## https://prometheus.io/docs/alerting/latest/configuration/#receiver
##
## Cuidado para substituir os nomes usando Camel Case (https://en.wikipedia.org/wiki/Camel_case)
## Isso quer dizer, por exemplo, que "email_configs" vira "emailConfigs".
##
prometheusOperator:

  ## Pontos de coleta através de ServiceMonitors.
  ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#servicemonitorspec
  ## Label selectors são adicionados automaticamente para restringir a coleta aos contêineres desta aplicação.
  ##
  ## IMPORTANTE: As portas usadas no ServiceMonitor PRECISAM ser declaradas no Pod.
  ##             Inclua as portas de métrica no Service deste chart, referenciando preferencialmente por nome.
  serviceMonitors: []
    # - name: mymetrics
    #   endpoints:
    #     ## Cada ServiceMonitor pode agrupar vários Endpoints de coleta.
    #     ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#endpoint
    #     - targetPort: 9404
    #       path: /metrics
    #       scheme: http
    #       params: {}
    #       interval: 30s
    #       scrapeTimeout: 15s

  ## Alertas que serão direcionados aos receivers desta aplicação.
  ## Para facilidade, o label "receiver" pode ser usado para indicar para onde
  ## o alerta deve ser enviado. Sem labels, o alerta será direcionado ao receiver
  ## padrão das rotas abaixo.
  ##
  ## Para uso avançado, labels podem ser livremente criados para serem usados nas rotas.
  ##
  ## CUIDADO: Nome do alerta não pode ter espacos. Será usado como nome do objeto Kubernetes.
  rules: []
    # - alert: AlertaQueVaiParaDiscord
    #   expr: |
    #     count(kube_deployment_created) < 0
    #   annotations:
    #     summary: Este alerta deve chegar no discord
    #     description: ""
    # - alert: AlertaQueVaiParaEmail
    #   expr: |
    #     count(kube_deployment_created) < 0
    #   labels:
    #     receiver: email
    #     # area: financeiro
    #   annotations:
    #     summary: Este alerta deve chegar no email
    #     description: ""

  ## Receivers que receberão os alertas definidos acima. Para uso
  ## simplificado, basta definir um receiver para que ele receba todos
  ## os alertas. Sua rota é criada automaticamente.
  ##
  ## Havendo mais de um receiver, o chart considera que o primeiro é
  ## o default usado para todos os alertas. Você pode sobrescrever o
  ## receiver default para todos os alertas informando o valor:
  ##
  ##    route:
  ##      receiver: nome-do-receiver
  ##
  ## Rotas padronizadas são criadas para cada receiver automaticamente.
  ## Para direcionar um determinado alerta ao receiver desejado, basta
  ## colocar um label no alerta:
  ##
  ##    receiver: nome-do-receiver
  ## 
  route:
    ## Receiver default é opcional. Vazio pega o primeiro da lista.
    # receiver: email

    ## Customiza intervalos para que sejam diferentes do global
    # groupBy: ["alertname"]
    # groupWait: 30s
    # groupInterval: 10s
    # repeatInterval: 1m
    
    ## CUIDADO: Deveria funcionar! Mas não funciona...
    ## Na versão atual do Operator, não faz efeito na rota criada.
    ## Pode ser ignorado por enquanto.
    # continue: "false"

    ## Defina sub-rotas somente se precisar de regras mais
    ## avançadas com base em labels customizados.
    # routes:
    #   - matchers:
    #       - name: area
    #         value: financeiro
    #     receiver: email
    #     groupBy: ["alertname"]
    #     groupWait: 30s
    #     groupInterval: 10s
    #     repeatInterval: 1m

    ## Confira a API Receiver do operator.
    ## https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#receiver
    ##
    ## A decleração dos headers também é diferente do formato original do Prometheus.
    ##
    receivers: []
      # - name: canalDiscord
      #   webhookConfigs:
      #     - url: 'http://discordbot.monitoria:9095'
      # - name: email
      #   emailConfigs:
      #   - to: 'email@example.com'
      #     sendResolved: true
      #     html: '{{ template "email.body.html" . }}'
      #     headers:
      #       - key: Subject
      #         value: '{{ template "email.subject.html" . }}'
